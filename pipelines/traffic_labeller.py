import logging
import random
from typing import Dict, List, Optional, Union

import pandas as pd
import tensorflow as tf
from common import PYTHON, FlowMixin, configure_logging, packages
from metaflow import (
    FlowSpec,
    Parameter,
    project,
    pypi_base,
    step,
)
from sagemaker import load_unlabeled_data

configure_logging()


@project(name="spam")
@pypi_base(
    python=PYTHON,
    packages=packages("pandas", "numpy", "boto3", "requests", "nltk", "Faker",
                      "tiktoken", "torch", "tensorflow"),
)
class SpamTraffic(FlowSpec, FlowMixin):
    """A pipeline for generating traffic or labeling data captured by a spam classifier model.

    This pipeline can send synthetic spam/non-spam text to a hosted model or generate ground truth
    labels using the data captured by the model.
    """
    action = Parameter(
        "action",
        help=(
            "The action you want to perform. The supported actions are 'traffic' for "
            "sending traffic to the endpoint and 'labeling' for labeling the data "
            "captured by the endpoint."
        ),
        default="traffic",
    )

    target = Parameter(
        "target",
        help=(
            "The target platform hosting the model. The supported values are 'local' "
            "for models hosted as a local inference service and 'sagemaker' for models "
            "hosted on a SageMaker endpoint."
        ),
        default="local",
    )

    target_uri = Parameter(
        "target-uri",
        help=(
            "The location where the pipeline will send the fake traffic or generate "
            "ground truth labels. If generating traffic, this parameter will point to "
            "the hosted model. If generating labels, this parameter will point to the "
            "location of the data captured by the model."
        ),
    )

    samples = Parameter(
        "samples",
        help=(
            "The number of samples that will be sent to the hosted model. Samples will "
            "be sent in batches of 10, so you might end up with a few more samples "
            "than the value you set for this parameter."
        ),
        default=200,
        required=False,
    )

    drift_proportion = Parameter(
        "drift-proportion",
        help=(
            "The proportion of the traffic that will synthetically generated"
            "The rest of the data will be from the original dataset"
        ),
        default=0.5,
        required=False,
    )

    drift_type = Parameter(
        "drift-type",
        help=(
            "The type of drift to introduce in the text samples. Options: "
            "'none': No drift, "
            "'vocabulary': Introduce new vocabulary/slang terms, "
            "'misspellings': Add misspellings to the text, "
            "'length': Change the length distribution of messages, "
            "'topics': Shift the topic distribution of messages, "
        ),
        default="none",
        required=False,
    )

    ground_truth_uri = Parameter(
        "ground-truth-uri",
        help=(
            "When labeling data captured by a SageMaker endpoint, this parameter "
            "specifies the S3 location where the ground truth labels will be stored. "
        ),
        required=False,
    )

    ground_truth_quality = Parameter(
        "ground-truth-quality",
        help=(
            "This parameter represents how similar the ground truth labels will be "
            "to the predictions generated by the model. Setting this parameter to a "
            "value less than 1.0 will introduce noise in the labels to simulate "
            "inaccurate model predictions."
        ),
        default=0.9,
        required=False,
    )

    @step
    def start(self):
        """Start the pipeline and load or generate the dataset."""
        if self.action not in ["traffic", "labeling"]:
            message = "The specified action is not supported."
            raise RuntimeError(message)

        if self.target not in ["local", "sagemaker"]:
            message = "The specified target is not supported."
            raise RuntimeError(message)

        if self.drift_type not in ["none", "vocabulary", "misspellings", "length", "topics", "mixed"]:
            message = "The specified drift type is not supported."
            raise RuntimeError(message)

        self.data = self.load_dataset()
        self.next(self.prepare_data)

    @step
    def prepare_data(self):
        """
        Prepare the data: generate synthetic data if needed, sample original data,
        apply drift ONLY to synthetic data if specified, and combine them.
        """
        import pandas as pd  # Ensure pandas is imported locally if needed

        # Default to using the original data if no mixing/drift is requested
        final_data_list = []
        original_data_to_use = self.data.copy()  # Start with the data loaded in 'start"
        if self.action == "traffic":
        # Determine if synthetic data generation/mixing is needed
            if self.drift_type != "none" and self.drift_proportion > 0:
                logging.info(
                    f"Preparing data: Mixing synthetic data and/or applying drift. "
                    f"Drift type requested: {self.drift_type}. "
                    f"Drift proportion: {self.drift_proportion}."
                )

                # --- Synthetic Data Handling ---
                num_synthetic = int(self.samples * self.drift_proportion)
                if num_synthetic > 0:
                    logging.info(f"Generating approximately {num_synthetic} synthetic samples.")
                    # Generate synthetic data (includes 'text' and 'ground_truth')
                    synthetic_data = self._generate_synthetic_data_scaled(
                        num_synthetic)  # Using the scaled version from previous example

                    # Apply drift ONLY to the synthetic data if drift_type is not 'none'
                    if self.drift_type != "none" and not synthetic_data.empty:
                        logging.info(f"Applying {self.drift_type} drift to SYNTHETIC data...")
                        # Pass a copy if you want to keep the original synthetic data unmodified
                        # Otherwise, modify in place (as _introduce_drift seems to do)
                        synthetic_data = self._introduce_drift(synthetic_data)  # Apply drift
                    else:
                        logging.info(
                            "No drift applied to synthetic data (drift_type is 'none' or no synthetic data generated).")

                    # Remove ground truth from synthetic data before adding to final list
                    if "ground_truth" in synthetic_data.columns:
                        synthetic_data.pop("ground_truth")

                    # Add the (potentially drifted) synthetic data to our list
                    if not synthetic_data.empty:
                        final_data_list.append(synthetic_data)
                else:
                    logging.info("Skipping synthetic data generation as drift_proportion is 0.")

                # --- Original Data Handling ---
                # Calculate how many original samples are needed to reach target 'self.samples'
                num_synthetic_actual = len(
                    synthetic_data) if 'synthetic_data' in locals() and not synthetic_data.empty else 0
                num_original_needed = self.samples - num_synthetic_actual
                if num_original_needed < 0: num_original_needed = 0  # Cannot be negative

                logging.info(f"Need {num_original_needed} original samples.")

                if num_original_needed > 0 and not self.data.empty:
                    # Sample the required number of original samples
                    n_sample = min(num_original_needed, len(self.data))  # Don't sample more than available
                    logging.info(f"Sampling {n_sample} original samples.")
                    original_data_to_use = self.data.sample(n=n_sample)
                elif num_original_needed <= 0:
                    logging.info("No original samples needed as synthetic samples meet or exceed target.")
                    original_data_to_use = pd.DataFrame()  # Use an empty DF for original data
                else:  # num_original_needed > 0 but self.data is empty
                    logging.info("Original samples needed, but no original data available.")
                    original_data_to_use = pd.DataFrame()

                # Remove ground truth from the selected original data (if exists and df not empty)
                if not original_data_to_use.empty and "ground_truth" in original_data_to_use.columns:
                    original_data_to_use.pop("ground_truth")

                # Add the selected original data to our list
                if not original_data_to_use.empty:
                    final_data_list.append(original_data_to_use)

                # --- Combine Data ---
                if final_data_list:
                    self.data = pd.concat(final_data_list, ignore_index=True)
                    # Shuffle the final combined dataset
                    self.data = self.data.sample(frac=1).reset_index(drop=True)
                    logging.info(
                        f"Combined dataset created with {len(self.data)} samples (drift applied only to synthetic part).")
                else:
                    logging.warning("Resulting dataset for traffic is empty after preparation.")
                    self.data = pd.DataFrame(
                        columns=['text'])  # Ensure self.data exists as an empty DataFrame with 'text' column

            else:
                # Case: No drift proportion AND drift_type is 'none'
                # Just use the original data, remove ground truth if present
                logging.info(f"Using original dataset ({len(self.data)} samples) without modification for traffic.")
                if not self.data.empty and "ground_truth" in self.data.columns:
                    self.data.pop("ground_truth")

            # Ensure self.data always has a 'text' column expected by downstream steps, even if empty
            if 'text' not in self.data.columns:
                self.data['text'] = None

        self.next(self.traffic)



    @step
    def traffic(self):
        """Prepare the payload and send traffic to the hosted model."""
        import boto3
        import pandas as pd

        if self.action == "traffic":
            self.dispatched_samples = 0

            try:
                if self.target == "sagemaker":
                    sagemaker_runtime = boto3.Session().client("sagemaker-runtime")

                while self.dispatched_samples < self.samples:
                    payload = {}

                    batch = self.data.sample(n=10)
                    payload["inputs"] = [
                        {
                            k: (None if pd.isna(v) else v)
                            for k, v in row.to_dict().items()
                        }
                        for _, row in batch.iterrows()
                    ]

                    if self.target == "local":
                        self._invoke_local_endpoint(payload)
                    elif self.target == "sagemaker":
                        self._invoke_sagemaker_endpoint(
                            sagemaker_runtime,
                            payload,
                        )

                    self.dispatched_samples += len(batch)
            except Exception:
                logging.exception("There was an error sending traffic to the endpoint.")

        self.next(self.labeling)


    @step
    def labeling(self):
        """Generate ground truth labels for unlabeled data captured by the model."""
        if self.action == "labeling":
            if self.target == "local":
                self.labeled_samples = self._label_sqlite_data()
            elif self.target == "sagemaker":
                self.labeled_samples = self._label_sagemaker_data()

        self.next(self.end)

    @step
    def end(self):
        """End of the pipeline."""
        if self.action == "traffic":
            logging.info(
                "Dispatched %s samples to the hosted model.",
                self.dispatched_samples,
            )
            if self.drift_type != "none":
                logging.info(
                    "Applied %s drift with intensity %s.",
                    self.drift_type
                )
        elif self.action == "labeling":
            logging.info("Labeled %s samples.", self.labeled_samples)

    def _generate_synthetic_data_scaled(self, num_total_synthetic_samples):
        """Generate synthetic spam and non-spam messages."""
        import pandas as pd
        import nltk
        from faker import Faker

        # Download required NLTK resources (consider moving to start or a setup step)
        try:
            nltk.data.find('corpora/wordnet')
        except LookupError:
            nltk.download('wordnet')

        fake = Faker()
        data = []

        # Aim for roughly half spam, half ham
        num_spam_to_generate = num_total_synthetic_samples // 2
        num_ham_to_generate = num_total_synthetic_samples - num_spam_to_generate

        # --- (Keep the existing spam_phrases, spam_templates, ham_templates definitions) ---
        spam_phrases = [
            "URGENT", "FREE", "WINNER", "CONGRATULATIONS", "LIMITED TIME",
            "DISCOUNT", "CASH PRIZE", "ACT NOW", "CLAIM YOUR", "EXCLUSIVE OFFER",
            "GET RICH", "GUARANTEED", "INVESTMENT", "NO RISK", "OPPORTUNITY",
            "SAVE BIG", "MIRACLE", "LOSE WEIGHT", "AMAZING", "FANTASTIC",
            "$$", "!!!", "???"
        ]
        spam_templates = [
            "URGENT: {company} {action}! {claim}!",
            "CONGRATULATIONS! You've been selected for {prize}! {claim}!",
            "{company} {announcement}. {claim} before {deadline}!",
            "FREE {product} for the first {number} customers! {action} now!",
            "{discount}% OFF on all {product}s. Limited time offer!",
            "Make {amount} working from home! {testimonial}",
            "WINNER: {prize} waiting for you! Click to {action}",
            "Your {service} subscription requires urgent {action}",
            "Your {account} will be {consequence} unless you {action} now",
            "Important: {consequence} - {action} required"
        ]
        ham_templates = [
            "Hi, just checking in about {topic}. {question}",
            "Thanks for your {item}. {response}",
            "Meeting scheduled for {time} regarding {topic}.",
            "Please review the {document} and provide feedback by {deadline}.",
            "Hope you're doing well. {message}",
            "FYI: {information} - let me know if you have questions.",
            "Just a reminder about {event} on {date}.",
            "Could you help me with {task} when you get a chance?",
            "I'm working on {project} and wanted to ask {question}",
            "Good news! {positive_update} - more details soon."
        ]
        # --- (End of template definitions) ---


        # Generate spam messages
        for _ in range(num_spam_to_generate):
            template = random.choice(spam_templates)
            # --- (Keep the existing text generation logic using .format) ---
            text = template.format(
                company=fake.company(),
                action=random.choice(["act now", "respond immediately", "click here", "verify your account"]),
                claim=random.choice(["Claim now", "Don't miss out", "While supplies last", "Time-sensitive"]),
                prize=random.choice(["$10,000 cash prize", "luxury vacation", "free iPhone", "shopping spree"]),
                announcement=random.choice(["special offer", "new promotion", "customer rewards", "loyalty bonus"]),
                deadline=random.choice(["midnight", "today", "this weekend", "24 hours"]),
                product=random.choice(["product", "smartphone", "vacation", "supplement"]),
                number=random.choice(["50", "100", "500", "1000"]),
                discount=str(random.randint(50, 90)),
                amount=f"${random.randint(1000, 10000)}",
                testimonial=random.choice(
                    ["I did it and you can too!", "No experience needed!", "So easy!", "100% guaranteed!"]),
                service=random.choice(["cloud storage", "email", "account", "subscription"]),
                account=random.choice(["account", "profile", "membership", "subscription"]),
                consequence=random.choice(["suspended", "terminated", "restricted", "flagged"])
            )
            # --- (End of text generation logic) ---


            if random.random() < 0.7: text = text + " " + random.choice(spam_phrases)
            if random.random() < 0.4: text = text.upper()
            data.append({"text": text, "ground_truth": "spam"})

        # Generate ham (non-spam) messages
        for _ in range(num_ham_to_generate):
            template = random.choice(ham_templates)
            # --- (Keep the existing text generation logic using .format) ---
            text = template.format(
                topic=random.choice(["the project", "our meeting", "the proposal", "your request"]),
                question=random.choice(["When are you free?", "What do you think?", "Can we discuss?", "Any updates?"]),
                item=random.choice(["email", "report", "feedback", "help"]),
                response=random.choice(["I appreciate it.", "That's helpful.", "Looking forward to working together.",
                                        "Let me know if you need more information."]),
                time=f"{random.randint(1, 12)}:{random.choice(['00', '15', '30', '45'])} {random.choice(['AM', 'PM'])}",
                document=random.choice(["report", "proposal", "contract", "presentation"]),
                deadline=random.choice(["tomorrow", "Friday", "next week", "end of day"]),
                message=random.choice(["Let's catch up soon.", "Hope you had a good weekend.", "Thanks for your help.",
                                       "Looking forward to hearing from you."]),
                information=random.choice(["schedule change", "updated document", "team announcement", "new policy"]),
                event=random.choice(["meeting", "conference call", "deadline", "team lunch"]),
                date=f"{random.choice(['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday'])} at {random.randint(1, 12)}{random.choice(['AM', 'PM'])}",
                task=random.choice(["question", "document", "project", "analysis"]),
                project=random.choice(
                    ["the quarterly report", "the client presentation", "our research", "the data analysis"]),
                positive_update=random.choice(
                    ["proposal approved", "project completed", "feedback received", "goals achieved"])
            )
            # --- (End of text generation logic) ---

            data.append({"text": text, "ground_truth": "ham"})

        # Shuffle the generated data before returning
        return pd.DataFrame(data).sample(frac=1).reset_index(drop=True)

    def _introduce_drift(self, df):
        """Introduce drift in the text data based on the specified drift type."""
        import pandas as pd
        import nltk
        from nltk.corpus import wordnet
        import random
        import re

        logging.info(f"Introducing {self.drift_type}")

        # Function to introduce vocabulary drift (new terms, slang)
        def apply_vocabulary_drift(text):  # Added message_type for potential future use
            import re
            import random
            """Introduce vocabulary drift while maintaining grammatical coherence"""

            # --- Existing Spam-focused patterns ---
            spam_replacement_patterns = {
                # Adjectives and emphasis
                r'\bURGENT\b': ['CRUCIAL', 'RED ALERT', 'HOT DROP'],
                r'\bCONGRATULATIONS\b': ['YO!', 'EZ WIN!', 'YOU MADE IT â€“'],
                r'\bImportant\b': ['Key', 'Major', 'Priority'],
                # Can also be ham, but context of spam makes it stronger
                r'\bFREE\b': ['Zero-Cost', 'No-Cap', 'Freebie'],

                # Nouns
                r'\bcustomers\b': ['degens', 'apes', 'early birds'],
                r'\bWINNER\b': ['SCORED', 'TOP SHOT', 'SWEEPED'],
                r'\bsubscription\b': ['plan', 'sub', 'tier'],  # 'sub' and 'tier' can be neutral too
                r'\boffer\b': ['alpha drop', 'moonshot', 'deal'],  # 'deal' can be neutral
                r'\baction\b': ['tap in', 'ape in', 'lock it'],
                r'\bannouncement\b': ['leak', 'drop', 'signal'],
                r'\bdeadline\b': ['cutoff', 'final block', 'end date'],  # 'end date', 'cutoff' can be neutral

                # Verbs
                r'\bClick\b': ['Smash', 'Tap', 'Hit'],
                r'\bMake\b': ['Stack', 'Farm', 'Print'],  # As in "Make $1000"
                r'\brequires\b': ['needs', 'demands', 'calls for'],  # 'needs', 'calls for' can be neutral
                r'\bwill be\b': ['gonna be', 'getting', 'set to be'],  # 'gonna be', 'set to be' can be neutral
            }

            spam_phrase_replacements = [
                (r'limited time offer', 'limited-time alpha drop'),
                (r'for the first 100 customers', 'for the first 100 degens'),
                (r'working from home', 'grinding remote'),
                (r'waiting for you', 'locked and loaded for you'),
                (r'Click to', 'Tap in to'),
                (r'action required', 'tap-in needed'),
                (r'special discount', 'moonbag markdown'),
                (r'exclusive deal', 'whitelist alpha'),
                # (r'provide feedback', 'drop your take'), # This could be ham-like too
                # (r'just checking in', 'pinging you real quick'), # This is definitely more ham-like
                # (r'let me know', 'hit me back'), # "hit me back" is spammy/aggressive, "ping me" is ham
                # (r'good news', 'fresh alpha'), # "fresh alpha" is spammy crypto slang
                # (r'reminder about', 'ping on'), # "ping on" is more ham-like
                # (r'FYI', 'just so you know'), # "just so you know" is neutral/ham
            ]

            # --- New Ham-focused patterns ---
            ham_replacement_patterns = {
                # Greetings & Politeness
                r'\bHi\b': ['Hey', 'Hello', 'Alright'],
                r'\bThanks\b': ['Cheers', 'Appreciate it', 'Many thanks', 'Thx'],
                r'\nPlease\b': ['Kindly', 'If you could', 'Could you please'],
                # "Kindly" can sometimes be scammy, but often formal ham
                r'\bHope\b': ['Trusting', 'Assuming'],  # e.g., "Hope you're well" -> "Trusting you're well"

                # Nouns
                r'\bmeeting\b': ['sync', 'catch-up', 'huddle', 'call', 'session'],
                r'\bdocument\b': ['doc', 'file', 'deck', 'report', 'item'],  # 'deck' for presentations
                r'\bfeedback\b': ['thoughts', 'input', 'take', 'suggestions', 'comments'],
                r'\bproject\b': ['initiative', 'task', 'workstream', 'assignment'],
                r'\btopic\b': ['item', 'subject', 'point', 'matter', 'issue'],
                r'\bquestion\b': ['query', 'q', 'inquiry'],
                r'\binformation\b': ['info', 'details', 'updates', 'specs'],
                r'\bdeadline\b': ['due date', 'target date', 'cutoff point'],  # 'cutoff' from spam can also fit here
                r'\breport\b': ['summary', 'write-up', 'analysis', 'briefing'],
                r'\bproposal\b': ['pitch', 'suggestion', 'plan', 'submission'],
                r'\bemail\b': ['message', 'note', 'comm'],

                # Verbs
                r'\breview\b': ['eyeball', 'check out', 'scan', 'look over', 'assess'],
                r'\bprovide\b': ['share', 'give', 'offer', 'submit'],
                r'\bhelp\b': ['assist', 'support', 'lend a hand', 'guide'],
                r'\bdiscuss\b': ['chat about', 'go over', 'talk through', 'cover'],
                r'\bscheduled\b': ['booked', 'set for', 'lined up', 'planned'],
                r'\bchecking\b': ['pinging', 'touching base on', 'following up on'],  # As in "checking in"
                r'\bworking\b': ['tackling', 'handling', 'on', 'developing'],  # As in "working on"
                r'\bremind\b': ['nudge', 'flag', 'highlight'],
                r'\bask\b': ['inquire', 'query', 'request clarification on'],

                # Adjectives/Adverbs
                r'\bgood\b': ['great', 'positive', 'excellent', 'solid'],  # As in "good news"
                r'\bsoon\b': ['shortly', 'in a bit', 'before long', 'swiftly'],
                r'\babout\b': ['re:', 'regarding', 'concerning', 'on the topic of'],  # Preposition
            }

            ham_phrase_replacements = [
                (r'just checking in about', ['quick ping on', 'just wanted to touch base re:', 'following up about']),
                (r'Thanks for your', ['Cheers for the', 'Appreciate your', 'Thanks much for the']),
                (r'Meeting scheduled for', ['Meeting.s set for', 'Catch-up booked for', 'We.re on for']),
                (r'Please review the',
                 ['Could you eyeball the', 'Keen for your eyes on the', 'Please take a look at the']),
                (r'provide feedback by', ['share your thoughts by', 'drop your take by', 'get your input by']),
                (r'Hope you.re doing well', ['Hope you.re good.', 'Trust you.re well.', 'Hope all is fine.']),
                (r'FYI', ['Heads up:', 'Just an FYI:', 'For your information:', 'JSYK:']),  # JSYK = Just So You Know
                (r'Just a reminder about', ['Quick reminder on', 'Friendly nudge re:', 'Just flagging the']),
                (
                r'Could you help me with', ['Can you lend a hand with', 'Need your brain on', 'Could you assist with']),
                (r'I.m working on', ['Currently tackling', 'Heads down on', 'I.m on the']),
                (r'Good news!', ['Great news!', 'Pleased to share that', 'Happy to report that']),
                (r'When are you free?', ['When.s good for you?', 'Got a window?', 'What.s your availability like?']),
                (r'What do you think?', ['Your thoughts?', 'What.s your take?', 'Keen to hear your view.']),
                (r'Let me know', ['Holler if', 'Ping me if', 'Keep me posted', 'LUK (Let Us Know)']),
                (r'Looking forward to hearing from you',
                 ['Keen to hear back.', 'Looking forward to your reply.', 'Awaiting your feedback.']),
                (r'Let.s catch up soon', ['Let.s sync soon.', 'Chat soon.', 'Let.s touch base shortly.']),
                (r'Can we discuss', ['Can we chat about', 'Shall we go over', 'Can we talk through']),
                (r'more details soon',
                 ['more info to follow', 'will share more shortly', 'further details coming soon']),
                (r'provide feedback by end of day',
                 ['get your thoughts by EOD', 'input by close of play', 'feedback by COB']),
                (r'Hope you had a good weekend', ['Hope your weekend was good.', 'Trust you had a restful weekend.']),
                (r'Thanks for your help',
                 ['Appreciate your assistance.', 'Thanks for the support.', 'Big thanks for helping out.']),
            ]

            # Combine original spam patterns with new ham patterns
            # If a key exists in both, the latter one (ham) would overwrite the spam one if merged directly.
            # For this reason, it's better to select which dictionary to use based on message_type,
            # or apply them selectively. For now, let's assume we want to expand the pool.
            # A simple merge might not be ideal if keys clash with different *intents*.
            # For this example, we'll make them additive, but be mindful of key clashes.

            # For simplicity in this example, we'll just make all patterns available.
            # In a more robust system, you might select patterns based on `message_type`.
            all_replacement_patterns = spam_replacement_patterns.copy()
            all_replacement_patterns.update(
                ham_replacement_patterns)  # ham patterns can overwrite spam if keys are identical

            all_phrase_replacements = spam_phrase_replacements + ham_phrase_replacements
            # Ensure phrase replacements offer choices if the replacement is a list
            processed_phrase_replacements = []
            for pattern, replacement in all_phrase_replacements:
                if isinstance(replacement, list):
                    processed_phrase_replacements.append((pattern, random.choice(replacement)))
                else:
                    processed_phrase_replacements.append((pattern, replacement))

            # First apply phrase-level substitutions
            for pattern, replacement in processed_phrase_replacements:  # Use the processed list
                text = re.sub(pattern, replacement, text, flags=re.IGNORECASE)

            # Then apply word-level substitutions
            words = text.split()
            for i in range(len(words)):
                # Strip punctuation for matching, but preserve it for replacement later
                # This helps match words like "well." or "Thanks,"
                original_word = words[i]
                # Simple punctuation check: common sentence enders or commas
                punctuation_suffix = ""
                if original_word.endswith(('.', ',', '!', '?')):
                    word_for_match = original_word[:-1]
                    punctuation_suffix = original_word[-1]
                else:
                    word_for_match = original_word

                for pattern, replacements in all_replacement_patterns.items():  # Use combined patterns
                    if re.fullmatch(pattern, word_for_match, flags=re.IGNORECASE):
                        new_word_core = word_for_match  # Default to original word core

                        if i > 0 and words[i - 1].lower() in ['a', 'an', 'the']:
                            valid_replacements = [
                                r for r in replacements
                                # Check if the first letter of the replacement is a vowel
                                if r[0].lower() in 'aeiou' and words[i - 1].lower() == 'an' or \
                                   r[0].lower() not in 'aeiou' and words[i - 1].lower() == 'a' or \
                                   words[i - 1].lower() == 'the'  # 'the' can precede vowel or consonant
                            ]
                            if valid_replacements:
                                new_word_core = random.choice(valid_replacements)
                        else:
                            new_word_core = random.choice(replacements)

                        # Preserve original case if the new word is not an acronym/special case
                        # And re-attach punctuation
                        if word_for_match.istitle() and not new_word_core.isupper():
                            words[i] = new_word_core.capitalize() + punctuation_suffix
                        elif word_for_match.isupper() and len(
                                word_for_match) > 1:  # Avoid making single letters like 'I' or 'A' all upper
                            # If original was all upper, make replacement all upper unless it's a "mixed case" new word
                            if not any(c.islower() for c in new_word_core):  # e.g. "JSYK" should stay as is
                                words[i] = new_word_core.upper() + punctuation_suffix
                            else:  # handles cases like "JSYK" or "re:" which have specific casing
                                words[i] = new_word_core + punctuation_suffix
                        else:
                            words[i] = new_word_core + punctuation_suffix
                        break
            return ' '.join(words)

        # Function to change length distribution
        def apply_length_drift(text):

            # Either shorten or lengthen
            if random.random() < 0.5:
                # Shorten: keep only first part of the message
                words = text.split()
                keep_ratio = max(0.3, 1 - random.random())
                return " ".join(words[:max(3, int(len(words) * keep_ratio))])
            else:
                # Lengthen: add filler text
                fillers = [
                    "As I mentioned earlier,",
                    "Please note that",
                    "I want to emphasize that",
                    "It's important to remember that",
                    "Just to let you know,",
                    "For your information,",
                    "To be clear,",
                    "In other words,",
                    "To put it differently,",
                    "As a matter of fact,"
                ]

                # Add 1-3 fillers depending on intensity
                num_fillers = random.randint(1, 4)
                chosen_fillers = random.sample(fillers, min(num_fillers, len(fillers)))

                # 50% chance to add at beginning, 50% chance to add at end
                if random.random() < 0.5:
                    return " ".join(chosen_fillers) + " " + text
                else:
                    return text + " " + " ".join(chosen_fillers)

        # Apply the specified drift type
        if self.drift_type == "vocabulary":
            df["text"] = df["text"].apply(apply_vocabulary_drift)
        elif self.drift_type == "length":
            df["text"] = df["text"].apply(apply_length_drift)
        elif self.drift_type == "mixed":
            # Apply a random mix of drift types to each sample
            for idx, row in df.iterrows():
                text = row["text"]
                drift_funcs = [apply_vocabulary_drift, apply_length_drift]

                # Apply 1-3 drift functions randomly
                num_drifts = random.randint(1, 3)
                selected_drifts = random.sample(drift_funcs, num_drifts)

                for drift_func in selected_drifts:
                    text = drift_func(text)

                df.at[idx, "text"] = text

        return df


    def _invoke_local_endpoint(self, payload):
        """Submit the given payload to a local inference service."""
        import json

        import requests

        payload["params"] = {"data_capture": True}
        predictions = requests.post(
            url=self.target_uri,
            headers={"Content-Type": "application/json"},
            data=json.dumps(payload),
            timeout=60,
        )

        return predictions.json()

    def _invoke_sagemaker_endpoint(self, sagemaker_runtime, payload):
        """Submit the given payload to a SageMaker endpoint."""
        import json

        response = sagemaker_runtime.invoke_endpoint(
            EndpointName=self.target_uri,
            ContentType="application/json",
            Body=json.dumps(payload),
        )

        return json.loads(response["Body"].read().decode())

    def _get_label(self, classification):
        """Generate a ground truth label for a spam classification.

        This simulates the ground truth labeling process with a certain quality level.
        """
        import random

        # If we have the actual label from synthetic data, use it as a reference
        return (
            classification
            if random.random() < self.ground_truth_quality
            else random.choice(["spam", "not spam"])
        )

    def _label_sqlite_data(self):
        """Generate ground truth labels for data captured by a local inference service.

        This function loads any unlabeled data from the SQLite database where the data
        was stored by the model and generates fake ground truth labels for it.
        """
        import sqlite3

        import pandas as pd

        connection = sqlite3.connect(self.target_uri)

        # We want to return any unlabeled samples from the database.
        df = pd.read_sql_query("SELECT * FROM data WHERE ground_truth IS NULL", connection)
        logging.info("Loaded %s unlabeled samples from the database.", len(df))

        # If there are no unlabeled samples, we don't need to do anything else.
        if df.empty:
            return 0

        for _, row in df.iterrows():
            uuid = row["uuid"]
            label = self._get_label(row["classification"])

            # Update the database
            update_query = "UPDATE data SET ground_truth = ? WHERE uuid = ?"
            connection.execute(update_query, (label, uuid))

        connection.commit()
        connection.close()

        return len(df)

    def _label_sagemaker_data(self):
        """Generate ground truth labels for data captured by a SageMaker endpoint.

        This function loads any unlabeled data from the location where SageMaker stores
        the data captured by the endpoint and generates fake ground truth labels. The
        function stores the labels in the specified S3 location.
        """
        import json
        from datetime import datetime, timezone

        import boto3

        if not self.ground_truth_uri:
            message = "The 'ground-truth-uri' parameter is required."
            raise RuntimeError(message)

        # Let's make sure the ground truth uri ends with a '/'
        ground_truth_uri = self.ground_truth_uri.rstrip("/") + "/"

        s3_client = boto3.client("s3")

        data = load_unlabeled_data(
            s3_client,
            self.target_uri,
            ground_truth_uri,
        )

        logging.info("Loaded %s unlabeled samples from S3.", len(data))

        # If there are no unlabeled samples, we don't need to do anything else.
        if data.empty:
            return 0

        records = []
        for event_id, group in data.groupby("event_id"):
            classifications = []
            for _, row in group.iterrows():
                classifications.append(self._get_label(row["classification"]))

            record = {
                "groundTruthData": {
                    # For testing purposes, we will generate a random
                    # label for each request.
                    "data": classifications,
                    "encoding": "CSV",
                },
                "eventMetadata": {
                    # This value should match the id of the request
                    # captured by the endpoint.
                    "eventId": event_id,
                },
                "eventVersion": "0",
            }

            records.append(json.dumps(record))

        ground_truth_payload = "\n".join(records)
        upload_time = datetime.now(tz=timezone.utc)
        uri = (
            "/".join(ground_truth_uri.split("/")[3:])
            + f"{upload_time:%Y/%m/%d/%H/%M%S}.jsonl"
        )

        s3_client.put_object(
            Body=ground_truth_payload,
            Bucket=ground_truth_uri.split("/")[2],
            Key=uri,
        )

        return len(data)


if __name__ == "__main__":
    SpamTraffic()
